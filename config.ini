[BASE]
base_directory = ./
base_io_directory = ${BASE_DIRECTORY}${BASE_IO_DIRECTORY_PREFIX}
base_io_directory_prefix = io
root_models_prefix = input/model/
root_outputs_prefix = output/model/
model_name = v1-5-pruned-emaonly
clip_model_name = vit-large-patch14
checkpoint = v1-5-pruned-emaonly.safetensors

[ROOT_DIRS]
root_models_dir = ${BASE:base_io_directory}/${BASE:root_models_prefix}
root_outputs_dir = ${BASE:base_io_directory}/${BASE:root_outputs_prefix}

[MODELS_DIRS]
sd_default_model_dir = ${ROOT_DIRS:ROOT_MODELS_DIR}${BASE:MODEL_NAME}
clip_models_dir = ${ROOT_DIRS:ROOT_MODELS_DIR}clip

[SUBMODELS_DIRS]
text_embedder_dir = ${MODELS_DIRS:CLIP_MODELS_DIR}/text_embedder/
image_encoder_dir = ${MODELS_DIRS:CLIP_MODELS_DIR}/image_encoder/

[STABLE_DIFFUSION_PATHS]
checkpoint_path = ./io/input/model/v1-5-pruned-emaonly.safetensors
text_embedder_path = ./io/input/model/clip/text_embedder.safetensors
unet_path = ./io/input/model/v1-5-pruned-emaonly/unet.safetensors
autoencoder_path = ./io/input/model/v1-5-pruned-emaonly/autoencoder.safetensors
latent_diffusion_path = ./io/input/model/v1-5-pruned-emaonly/latent_diffusion.safetensors

[CLIP_PATHS]
image_processor_path = ./io/input/model/clip/image_encoder/image_processor.ckpt
clip_model_path = ./io/input/model/clip/image_encoder/clip_model.ckpt
image_encoder_path = ./io/input/model/clip/image_encoder/clip_image_encoder.ckpt
tokenizer_path = ./io/input/model/clip/text_embedder/tokenizer
text_model_path = ./io/input/model/clip/text_embedder/vit-large-patch14

