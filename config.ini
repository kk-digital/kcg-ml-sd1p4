[BASE]
base_directory = ./
base_io_directory = ${BASE_DIRECTORY}${BASE_IO_DIRECTORY_PREFIX}
base_io_directory_prefix = 
root_models_prefix = input/model/
root_outputs_prefix = output/model/
model_name = v1-5-pruned-emaonly
clip_model_name = vit-large-patch14
checkpoint = ${MODEL_NAME}.safetensors

[ROOT_DIRS]
root_models_dir = ${BASE:base_io_directory}${BASE:root_models_prefix}
root_outputs_dir = ${BASE:base_io_directory}${BASE:root_outputs_prefix}

[MODELS_DIRS]
sd_default_model_dir = ${ROOT_DIRS:ROOT_MODELS_DIR}${BASE:MODEL_NAME}/
clip_models_dir = ${ROOT_DIRS:ROOT_MODELS_DIR}clip/
clip_model_dir = ${MODELS_DIRS:CLIP_MODELS_DIR}${BASE:CLIP_MODEL_NAME}/
text_embedder_dir = ${MODELS_DIRS:CLIP_MODELS_DIR}text_embedder/
image_encoder_dir = ${MODELS_DIRS:CLIP_MODELS_DIR}image_encoder/

[SUBMODELS_DIRS]
tokenizer_dir = ${MODELS_DIRS:TEXT_EMBEDDER_DIR}tokenizer/
text_model_dir = ${MODELS_DIRS:TEXT_EMBEDDER_DIR}text_model/
image_processor_dir = ${MODELS_DIRS:IMAGE_ENCODER_DIR}image_processor/
vision_model_dir = ${MODELS_DIRS:IMAGE_ENCODER_DIR}vision_model/

[STABLE_DIFFUSION_PATHS]
checkpoint_path = ./input/model/v1-5-pruned-emaonly.safetensors
unet_path = ./input/model/v1-5-pruned-emaonly/unet.safetensors
autoencoder_path = ./input/model/v1-5-pruned-emaonly/autoencoder.safetensors
latent_diffusion_path = ./input/model/v1-5-pruned-emaonly/latent_diffusion.safetensors

[CLIP_PATHS]
image_processor_path = ./input/model/clip/image_encoder/image_processor
vision_model_path = ./input/model/clip/image_encoder/vision_model
image_encoder_path = ./input/model/clip/image_encoder/image_encoder.safetensors
tokenizer_path = ./input/model/clip/text_embedder/tokenizer
text_model_path = ./input/model/clip/text_embedder/text_model
text_embedder_path = ./input/model/clip/text_embedder/text_embedder.safetensors

