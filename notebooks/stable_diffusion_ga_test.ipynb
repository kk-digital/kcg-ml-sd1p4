{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGX7E9X8bBcQ",
    "outputId": "ef4172bb-c437-47b3-f4a5-5cfb310a061a"
   },
   "outputs": [],
   "source": [
    "ENV_TYPE = \"TEST1\"\n",
    "\n",
    "if(ENV_TYPE != \"TEST\"):\n",
    "  !git clone \"https://github.com/kk-digital/kcg-ml-sd1p4.git\"\n",
    "  %cd kcg-ml-sd1p4\n",
    "  !pip3 install -r requirements.txt\n",
    "  exit()\n",
    "else:\n",
    "  !pip3 install -r requirements.txt --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./download_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./process_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxVwKkBrW4_8",
    "outputId": "368636ec-3637-4557-e42a-9eb05c88dc72"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "if(os.getcwd() == \"/content\"):\n",
    "  %cd kcg-ml-sd1p4\n",
    "import torch\n",
    "from typing import List\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import safetensors as st\n",
    "from os.path import join\n",
    "\n",
    "from chad_score.chad_score import ChadScorePredictor\n",
    "from stable_diffusion import StableDiffusion\n",
    "from stable_diffusion.model.clip_text_embedder import CLIPTextEmbedder\n",
    "from stable_diffusion.model.clip_image_encoder import CLIPImageEncoder\n",
    "from stable_diffusion.utils_model import *\n",
    "from stable_diffusion.utils_backend import *\n",
    "from stable_diffusion.utils_model import initialize_latent_diffusion\n",
    "from stable_diffusion.utils_image import *\n",
    "from stable_diffusion.constants import IODirectoryTree\n",
    "from stable_diffusion.constants import TOKENIZER_PATH, TEXT_MODEL_PATH\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "\n",
    "base_dir = \"./\"\n",
    "sys.path.insert(0, base_dir)\n",
    "\n",
    "# Variables\n",
    "SEED = 0\n",
    "BATCH_SIZE = 1\n",
    "POPULATION_SIZE = 12\n",
    "GEN_IMAGE_N_GENERATIONS = 50\n",
    "CFG_STRENGTH = 9\n",
    "N_STEPS = 20\n",
    "EMBEDDED_PROMPTS_DIR = os.path.abspath(join(base_dir, \"./input/embedded_prompts/\"))\n",
    "OUTPUT_DIR = os.path.abspath(\n",
    "    os.path.join(base_dir, \"./output/ga/\")\n",
    ")\n",
    "IMAGES_DIR = os.path.abspath(join(OUTPUT_DIR, \"images/\"))\n",
    "FEATURES_DIR = os.path.abspath(join(OUTPUT_DIR, \"features/\"))\n",
    "\n",
    "NULL_PROMPT = \"\"\n",
    "# DEVICE = input(\"Set device: 'cuda:i' or 'cpu'\")\n",
    "DEVICE = get_device()\n",
    "\n",
    "print(EMBEDDED_PROMPTS_DIR)\n",
    "print(OUTPUT_DIR)\n",
    "print(IMAGES_DIR)\n",
    "print(FEATURES_DIR)\n",
    "\n",
    "os.makedirs(EMBEDDED_PROMPTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nFJ2YQPhLS9"
   },
   "outputs": [],
   "source": [
    "!git checkout genetic-algorithm\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqjrIYWnJhUz",
    "outputId": "b5ad8c70-484d-4193-8199-cace83af92a1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to generate prompts\n",
    "def generate_prompts(prompt_segments, num_prompts=6):\n",
    "    # Select 6 random segments from the prompt_segments list\n",
    "    selected_prompts = random.sample(prompt_segments, num_prompts)\n",
    "    modifiers = [\n",
    "        'beautiful', 'gorgeous', 'stunning', 'charming', 'captivating', 'breathtaking',\n",
    "        'masterpiece', 'exquisite', 'magnificent', 'majestic', 'elegant', 'sublime',\n",
    "        'ugly', 'hideous', 'grotesque', 'repulsive', 'disgusting', 'revolting',\n",
    "        'futuristic', 'cyberpunk', 'hi-tech', 'advanced', 'innovative', 'modern',\n",
    "        'fantasy', 'mythical', 'scifi', 'side scrolling', 'character', 'side scrolling',\n",
    "        'white background', 'centered', 'full character', 'no background', 'not centered',\n",
    "        'line drawing', 'sketch', 'black and white', 'colored', 'offset', 'video game']\n",
    "\n",
    "    # Add modifiers to the selected prompts and return them in a list (PROMPT)\n",
    "    return [f\"{random.choice(modifiers)} {prompt}\" for prompt in selected_prompts]\n",
    "\n",
    "# List of prompt segments\n",
    "prompt_segments = ['chibi', 'waifu', 'cyborg', 'dragon', 'android', 'nekomimi', 'mecha', 'kitsune', 'AI companion', 'furry detective', 'robot butler', 'futuristic steampunk', 'cybernetic implants',\n",
    "                   'anthropomorphic AI', 'mechanical wizard', 'kemonomimi', 'android rebellion', 'magical robot pet', 'intergalactic furball', 'cyberpunk android', 'shapeshifting furry',\n",
    "                   'mech pilot', 'furry time traveler']\n",
    "\n",
    "# Generate 6 random prompts with modifiers (initial population)\n",
    "PROMPT = generate_prompts(prompt_segments)\n",
    "\n",
    "# Print the generated prompts\n",
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dd_21FmhHA4B",
    "outputId": "91303384-7e90-446e-9c57-dd640199a697"
   },
   "outputs": [],
   "source": [
    "def embed_and_save_prompts(prompts: list):\n",
    "    null_prompt = \"\"\n",
    "    clip_text_embedder = CLIPTextEmbedder(device=get_device())\n",
    "    clip_text_embedder.load_submodels()\n",
    "\n",
    "    null_cond = clip_text_embedder(null_prompt)\n",
    "\n",
    "    # Initialize list to store embeds\n",
    "    embedded_prompts_list = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        # Embed each prompt individually\n",
    "        print(\"Generating prompt \", prompt)\n",
    "        embedded_prompt = clip_text_embedder(prompt)\n",
    "        embedded_prompts_list.append(embedded_prompt)\n",
    "\n",
    "    clip_text_embedder.to(\"cpu\")\n",
    "    del clip_text_embedder\n",
    "    torch.cuda.empty_cache()\n",
    "    get_memory_status()\n",
    "\n",
    "    return (embedded_prompts_list, null_cond)\n",
    "\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    import numpy as np\n",
    "\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "# Generate embeddings for each prompt\n",
    "embedding, null_prompt = embed_and_save_prompts(PROMPT)\n",
    "num_images = len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYH6CWsOMbR-"
   },
   "outputs": [],
   "source": [
    "# Load Stable Diffusion\n",
    "sd = StableDiffusion(device=DEVICE, n_steps=N_STEPS)\n",
    "sd.quick_initialize()\n",
    "sd.model.load_unet()\n",
    "sd.model.load_autoencoder().load_decoder()\n",
    "\n",
    "\n",
    "# Load chadscore and clip\n",
    "import clip\n",
    "\n",
    "# Test calculate chadscore\n",
    "chad = ChadScorePredictor(768)\n",
    "chad.load_model(\"./input/model/aesthetic_scorer/sac+logos+ava1-l14-linearMSE.pth\")\n",
    "image_features_clip_model, preprocess = clip.load(\"ViT-L/14\", device=get_device())  #RN50x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqPwnmEYeXod"
   },
   "outputs": [],
   "source": [
    "def generate_images_from_embeddings(embedded_prompts_array, null_prompt):\n",
    "  # 'embedded_prompts_array' is the array of shape (i, 77, 768)\n",
    "  image = sd.generate_images_from_embeddings(\n",
    "      seed=SEED, embedded_prompt=embedded_prompts_array[i:i+1], null_prompt=null_prompt\n",
    "  )\n",
    "  return image\n",
    "\n",
    "\n",
    "solution_reshaped = best_solution.reshape(1, 77, 768)\n",
    "solution_reshaped = torch.tensor(solution_reshaped, dtype=torch.float32)\n",
    "\n",
    "image = generate_images_from_embeddings(solution_reshaped, null_prompt)\n",
    "    pil_image = to_pil(image[0])\n",
    "    filename=f\"{IMAGES_DIR}/{generation}.png\"\n",
    "    pil_image.show()\n",
    "    pil_image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3VxFRyYQK_oq",
    "outputId": "d76e8d7d-e86f-45ca-ee78-3d9584cb1a43"
   },
   "outputs": [],
   "source": [
    "import pygad\n",
    "\n",
    "# Function to calculate the chad score for batch of images\n",
    "def calculate_chad_score(ga_instance, solution, solution_idx):\n",
    "  # Convert the solution back to the original shape (1, 77, 768)\n",
    "  solution_reshaped = solution.reshape(1, 77, 768)\n",
    "\n",
    "  # Convert the numpy array to a PyTorch tensor\n",
    "  solution_reshaped = torch.tensor(solution_reshaped, dtype=torch.float32)\n",
    "\n",
    "  # Copy the tensor to CUDA device if 'device' is 'cuda'\n",
    "  if device == 'cuda':\n",
    "    solution_reshaped = solution_reshaped.to(device)\n",
    "\n",
    "  # Generate an image using the solution\n",
    "  image = generate_images_from_embeddings(solution_reshaped, null_prompt)\n",
    "\n",
    "  pil_image = to_pil(image[0])  # Convert to (height, width, channels)\n",
    "\n",
    "  # If generation % 1 == 0 save\n",
    "  if(ga_instance.generations_complete % 2 == 0):\n",
    "    os.makedirs(f\"{IMAGES_DIR}/{ga_instance.generations_complete}\", exist_ok=True)\n",
    "    filename=f\"{IMAGES_DIR}/{ga_instance.generations_complete}/{idx}.png\"\n",
    "    pil_image.show()\n",
    "    pil_image.save(filename)\n",
    "\n",
    "  unsqueezed_image = preprocess(pil_image).unsqueeze(0).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    image_features = image_features_clip_model.encode_image(unsqueezed_image)\n",
    "\n",
    "    im_emb_arr = normalized(image_features.cpu().detach().numpy() )\n",
    "    prediction = chad(torch.from_numpy(im_emb_arr).to(device).type(torch.cuda.FloatTensor))\n",
    "    chad_score = prediction.item()\n",
    "  return chad_score\n",
    "\n",
    "# Define the GA loop function\n",
    "def genetic_algorithm_loop(sd, embedded_prompts, null_prompt, generations=10, population_size=POPULATION_SIZE, mutation_rate=0.4, num_parents_mating=2):\n",
    "\n",
    "    # Convert each tensor in the list to a 2D numpy array and store them in a new list\n",
    "    embedded_prompts_list = []\n",
    "    num_genes = embedded_prompts[0].shape[0] * embedded_prompts[0].shape[1]\n",
    "\n",
    "    for tensor in embedded_prompts:\n",
    "        tensor = tensor.cpu()\n",
    "        list_tensor = tensor.squeeze().tolist()\n",
    "        embedded_prompts_list.append(list_tensor)\n",
    "\n",
    "    # Turn into a numpy array\n",
    "    embedded_prompts_list = np.hstack(embedded_prompts_list)\n",
    "\n",
    "    # Initialize the GA\n",
    "    ga_instance = pygad.GA(num_generations=generations,\n",
    "                              num_parents_mating=num_parents_mating,\n",
    "                              fitness_func=calculate_chad_score,\n",
    "                              num_genes=num_genes,\n",
    "                              crossover_type=\"single_point\",\n",
    "                              initial_population=embedded_prompts_list,\n",
    "                              mutation_percent_genes=mutation_rate*100)\n",
    "\n",
    "\n",
    "    # Get the final best solution and images\n",
    "    best_solution, best_solution_fitness = ga_instance.best_solution()\n",
    "    best_solution = best_solution.reshape(1, 77, 768)  # Reshape the best solution to the correct shape\n",
    "    final_image = sd.generate_images_from_embeddings(embedded_prompt=best_solution, null_prompt=null_prompt)\n",
    "\n",
    "    # Save the final best solution images\n",
    "    final_filename=f\"{IMAGES_DIR}/final.png\"\n",
    "    pil_final = to_pil(final_image[0])\n",
    "    pil_final.show()\n",
    "    pil_final.save(final_filename)\n",
    "\n",
    "    return best_solution\n",
    "\n",
    "# Call the GA loop function with your initialized StableDiffusion model\n",
    "best_solution = genetic_algorithm_loop(sd, embedding, null_prompt)\n",
    "\n",
    "print(\"Best solution found!\")\n",
    "\n",
    "torch.save(embedded_prompts, join(EMBEDDED_PROMPTS_DIR, \"embedded_final_solution.pt\"))\n",
    "print(\"Saving solution...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UL-xzoZT8qvW"
   },
   "outputs": [],
   "source": [
    "# Clean unused loaded models\n",
    "del image_features_clip_model, sd"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
