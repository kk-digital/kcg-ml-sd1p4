{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kk-digital/kcg-ml-sd1p4\n",
    "%cd kcg-ml-sd1p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./download_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./process_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import shutil\n",
    "from torchvision.transforms import ToPILImage\n",
    "from os.path import join\n",
    "\n",
    "base_directory = \"../\"\n",
    "sys.path.insert(0, base_directory)\n",
    "\n",
    "output_base_dir = join(base_directory, \"./output/sd2-notebook/\")\n",
    "output_directory = join(output_base_dir, \"demo/\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(output_directory)\n",
    "except Exception as e:\n",
    "    print(e, \"\\n\", \"Creating the path...\")\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "from stable_diffusion import StableDiffusion\n",
    "from stable_diffusion.utils_backend import *\n",
    "from stable_diffusion.utils_image import *\n",
    "from stable_diffusion.utils_model import *\n",
    "from utility.utils_logger import *\n",
    "\n",
    "from stable_diffusion.constants import IODirectoryTree\n",
    "\n",
    "device = get_device()\n",
    "to_pil = lambda image: ToPILImage()(torch.clamp((image + 1.0) / 2.0, min=0.0, max=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = IODirectoryTree(base_directory)\n",
    "print(\n",
    "    pt.autoencoder\n",
    ")  # should be `.../kcg-ml-sd1p4/input/model/autoencoder/autoencoder.ckpt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the logistic distribution\n",
    "def logistic_distribution(loc, scale):\n",
    "    base_distribution = torch.distributions.Uniform(0, 1)\n",
    "    transforms = [\n",
    "        torch.distributions.transforms.SigmoidTransform().inv,\n",
    "        torch.distributions.transforms.AffineTransform(loc=loc, scale=scale),\n",
    "    ]\n",
    "    logistic = torch.distributions.TransformedDistribution(\n",
    "        base_distribution, transforms\n",
    "    )\n",
    "    return logistic\n",
    "\n",
    "\n",
    "noise_fn = (\n",
    "    lambda shape, device=device: logistic_distribution(loc=0.0, scale=0.5)\n",
    "    .sample(shape)\n",
    "    .to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty stable diffusion class\n",
    "stable_diffusion = StableDiffusion(device=device)\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a latent diffusion model so you can load its submodels from disk\n",
    "stable_diffusion.quick_initialize().load_submodel_tree(\n",
    "    **pt.latent_diffusion_submodels_tree\n",
    ")\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unload the latent diffusion model submodels and check memory usage, to test if the unloading works\n",
    "stable_diffusion.unload_model()\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize a new stable diffusion model with a ddim_eta parameter and load submodel tree\n",
    "ddim_eta = 0.0\n",
    "stable_diffusion = StableDiffusion(device=device, ddim_eta=ddim_eta)\n",
    "stable_diffusion.quick_initialize().load_submodel_tree(\n",
    "    **pt.latent_diffusion_submodels_tree\n",
    ")\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a temperature for the sampling (in general higher means more diversity but less quality) and generate an image, then save it and show it\n",
    "# temperature only makes any difference if `ddim_eta` is different from zero\n",
    "\n",
    "temperature = 1.0\n",
    "imgs = stable_diffusion.generate_images(\n",
    "    prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "    seed=2982,\n",
    "    noise_fn=noise_fn,\n",
    "    temperature=temperature,\n",
    ")\n",
    "save_images(\n",
    "    imgs,\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_sample_temp{temperature:.3f}_eta{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    ),\n",
    ")\n",
    "to_pil(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the ddim_eta parameter and generate another image, then save it and show it\n",
    "stable_diffusion.ddim_eta = 0.1\n",
    "temperature = 1.0\n",
    "imgs = stable_diffusion.generate_images(\n",
    "    prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "    seed=2982,\n",
    "    noise_fn=noise_fn,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "save_images(\n",
    "    imgs,\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_sample_temp{temperature:.3f}_eta{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    ),\n",
    ")\n",
    "to_pil(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher `ddim_eta`s imply higher noise levels\n",
    "stable_diffusion.ddim_eta = 0.5\n",
    "temperature = 1.0\n",
    "imgs = stable_diffusion.generate_images(\n",
    "    prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "    seed=2982,\n",
    "    noise_fn=noise_fn,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "save_images(\n",
    "    imgs,\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_sample_temp{temperature:.3f}_eta{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    ),\n",
    ")\n",
    "to_pil(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and so do higher temperatures\n",
    "stable_diffusion.ddim_eta = 0.5\n",
    "temperature = 1.8\n",
    "imgs = stable_diffusion.generate_images(\n",
    "    prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "    seed=2982,\n",
    "    noise_fn=noise_fn,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "save_images(\n",
    "    imgs,\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_sample_temp{temperature:.3f}_eta{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    ),\n",
    ")\n",
    "to_pil(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check how the images change with the ddim_eta parameter\n",
    "temperature = 1.0\n",
    "images = []\n",
    "eta_steps = 5\n",
    "eta_0 = 0.0\n",
    "for i in range(eta_steps):\n",
    "    ddim_eta = eta_0 + i * 0.1\n",
    "    stable_diffusion.ddim_eta = ddim_eta\n",
    "    imgs = stable_diffusion.generate_images(\n",
    "        prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "        seed=2982,\n",
    "        noise_fn=noise_fn,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    print(imgs.shape)\n",
    "    images.append(imgs)\n",
    "images = torch.cat(images, dim=0)\n",
    "grid = torchvision.utils.make_grid(\n",
    "    images, normalize=False, range=(-1, 1), scale_each=True, pad_value=0\n",
    ")\n",
    "grid_img = to_pil(grid)\n",
    "grid_img.save(\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_grid_temp{temperature:.3f}_eta{eta_0:.3f}-{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    )\n",
    ")\n",
    "grid_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can check how the images change with the temperature alone\n",
    "temperature = 1.0\n",
    "stable_diffusion.ddim_eta = 0.1\n",
    "images = []\n",
    "temp_steps = 5\n",
    "for i in range(temp_steps):\n",
    "    temperature += 0.1\n",
    "    imgs = stable_diffusion.generate_images(\n",
    "        prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "        seed=2982,\n",
    "        noise_fn=noise_fn,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    print(imgs.shape)\n",
    "    images.append(imgs)\n",
    "images = torch.cat(images, dim=0)\n",
    "grid = torchvision.utils.make_grid(\n",
    "    images,\n",
    "    normalize=False,\n",
    "    nrow=temp_steps,\n",
    "    range=(-1, 1),\n",
    "    scale_each=True,\n",
    "    pad_value=0,\n",
    ")\n",
    "grid_img = to_pil(grid)\n",
    "grid_img.save(\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_grid_temp{temperature-temp_steps*0.1:.3f}-{temperature:.3f}_eta{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    )\n",
    ")\n",
    "grid_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can vary both things simultaneously (ddim_eta on y-axis, temperature on x-axis; it increases from left to right and from top to bottom)\n",
    "grid_side = 2\n",
    "temperature = 1.0\n",
    "ddim_eta = 0.1\n",
    "grid = []\n",
    "# rows = []\n",
    "for i in range(grid_side + 1):\n",
    "    temperature += 0.2\n",
    "    for j in range(grid_side + 1):\n",
    "        stable_diffusion.ddim_eta = ddim_eta + j * 0.1\n",
    "        imgs = stable_diffusion.generate_images(\n",
    "            prompt=\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\",\n",
    "            seed=2982,\n",
    "            noise_fn=noise_fn,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        # rows.append(imgs)\n",
    "        grid.append(imgs)\n",
    "    # grid.append(torch.cat(rows, dim=0))\n",
    "\n",
    "tensor_grid = torch.cat(grid, dim=0)\n",
    "tensor_grid.shape\n",
    "grid = torchvision.utils.make_grid(\n",
    "    tensor_grid,\n",
    "    nrow=grid_side + 1,\n",
    "    normalize=False,\n",
    "    range=(-1, 1),\n",
    "    scale_each=True,\n",
    "    pad_value=0,\n",
    ")\n",
    "grid_img = to_pil(grid)\n",
    "grid_img.save(\n",
    "    join(\n",
    "        output_directory,\n",
    "        f\"test_grid_temp{temperature-grid_side*0.2:.3f}-{temperature:.3f}_eta{ddim_eta:.3f}-{stable_diffusion.ddim_eta:.3f}.png\",\n",
    "    )\n",
    ")\n",
    "grid_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
