{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import shutil\n",
    "from torchvision.transforms import ToPILImage\n",
    "from os.path import join\n",
    "\n",
    "base_directory = \"../\"\n",
    "sys.path.insert(0, base_directory)\n",
    "\n",
    "output_base_dir = join(base_directory, \"./output/sd2-notebook/\")\n",
    "output_directory = join(output_base_dir, \"unet/\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(output_directory)\n",
    "except Exception as e:\n",
    "    print(e, \"\\n\", \"Creating the path...\")\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "from stable_diffusion.stable_diffusion import StableDiffusion\n",
    "from stable_diffusion.utils_backend import *\n",
    "from stable_diffusion.utils_image import *\n",
    "from stable_diffusion.utils_model import *\n",
    "from stable_diffusion.utils_logger import *\n",
    "from stable_diffusion.constants import IODirectoryTree\n",
    "\n",
    "\n",
    "to_pil = lambda image: ToPILImage()(torch.clamp((image + 1.0) / 2.0, min=0.0, max=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = IODirectoryTree(base_directory=base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty stable diffusion class\n",
    "stable_diffusion = StableDiffusion(device=device)\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty latent diffusion model; it returns self.model\n",
    "stable_diffusion.quick_initialize()\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use the unet we first need conditioning context. we can use the clip embedder to get it.\n",
    "stable_diffusion.model.load_clip_embedder(**pt.embedder)\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embedder submodels, tokenizer and transformer\n",
    "stable_diffusion.model.clip_embedder.load_submodels(**pt.embedder_submodels)\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_diffusion.model.clip_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embedding for a prompt\n",
    "prompt_embedding = stable_diffusion.model.clip_embedder(\n",
    "    [\"A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memory_status()\n",
    "prompt_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need the embedder anymore, so we can unload it\n",
    "stable_diffusion.model.unload_clip_embedder()\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the prompt embedding\n",
    "torch.save(prompt_embedding, join(output_base_dir, \"prompt_embedding.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the latent diffusion class has a method to load the unet, since it is a submodel of it. it returns the unet model, wrapped in a DiffusionWrapper class.\n",
    "# it is accessible as self.model.model or through the alias self.model.unet\n",
    "stable_diffusion.model.load_unet(**pt.unet)\n",
    "get_memory_status()\n",
    "stable_diffusion.model.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an encoded image and get its shape\n",
    "encoded_img = torch.load(join(output_base_dir, \"encoded_img_tensor.pt\")).to(device)\n",
    "encoded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a latent representation of same shape as the encoded image\n",
    "sample = torch.randn_like(encoded_img)\n",
    "get_memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a timestep for this sample\n",
    "time_step = torch.tensor([0.0]).to(device)\n",
    "time_step.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict noise with the unet\n",
    "unet_output = stable_diffusion.model.unet(sample, time_step, prompt_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memory_status()\n",
    "unet_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(\n",
    "    unet_output.permute(1, 0, 2, 3),\n",
    "    nrow=2,\n",
    "    normalize=False,\n",
    "    range=(-1, 1),\n",
    "    scale_each=True,\n",
    "    pad_value=0,\n",
    ")\n",
    "dim_grid_image = to_pil(grid)\n",
    "dim_grid_image.save(join(output_directory, f\"unet_output.png\"))\n",
    "dim_grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_diffusion.model.unload_submodels()\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
