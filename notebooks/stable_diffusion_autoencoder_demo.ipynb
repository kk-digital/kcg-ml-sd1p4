{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpDvwi7kEAah"
   },
   "outputs": [],
   "source": [
    "ENV_TYPE = \"TEST\"\n",
    "\n",
    "if(ENV_TYPE != \"TEST\"):\n",
    "  !git clone \"https://github.com/kk-digital/kcg-ml-sd1p4.git\"\n",
    "  %cd kcg-ml-sd1p4\n",
    "  !pip3 install -r requirements.txt\n",
    "  exit()\n",
    "  base_directory = \"./\"\n",
    "else:\n",
    "  base_directory = \"../\"\n",
    "\n",
    "# Magical check for fixing all of our directory issues\n",
    "import subprocess\n",
    "output = subprocess.check_output([\"pwd\"], universal_newlines=True)\n",
    "if \"notebooks\" in output:\n",
    "    %cd ..\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCjgSKd9EAan"
   },
   "outputs": [],
   "source": [
    "!python3 ./download_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6mQKoSXEAao"
   },
   "outputs": [],
   "source": [
    "!python3 ./process_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJpDFLmiEAao"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import shutil\n",
    "from torchvision.transforms import ToPILImage\n",
    "from os.path import join\n",
    "\n",
    "base_directory = \"./\"\n",
    "sys.path.insert(0, base_directory)\n",
    "\n",
    "output_base_dir = join(base_directory, \"./output/sd2-notebook/\")\n",
    "output_directory = join(output_base_dir, \"autoencoder/\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(output_directory)\n",
    "except Exception as e:\n",
    "    print(e, \"\\n\", \"Creating the path...\")\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "from stable_diffusion.stable_diffusion import StableDiffusion\n",
    "from stable_diffusion.utils_backend import *\n",
    "from stable_diffusion.utils_image import *\n",
    "from stable_diffusion.utils_model import *\n",
    "from utility.utils_logger import logger\n",
    "from stable_diffusion.model_paths import IODirectoryTree\n",
    "from configs.model_config import ModelPathConfig\n",
    "\n",
    "to_pil = lambda image: ToPILImage()(torch.clamp((image + 1.0) / 2.0, min=0.0, max=1.0))\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woFboRTSEAap"
   },
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "sys.path.insert(0, base_dir)\n",
    "\n",
    "batch_size = 1\n",
    "model_config = ModelPathConfig()\n",
    "pt = IODirectoryTree(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4YEqSJ_EAap"
   },
   "outputs": [],
   "source": [
    "# initialize an empty stable diffusion class\n",
    "stable_diffusion = StableDiffusion(device=device)\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCwSucawEAaq"
   },
   "outputs": [],
   "source": [
    "# initialize an empty latent diffusion model; it returns self.model\n",
    "stable_diffusion.quick_initialize()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9akaLrwhEAaq"
   },
   "outputs": [],
   "source": [
    "# the latent diffusion class has a method to load the autoencoder, since it is a submodel of it. it returns the autoencoder\n",
    "stable_diffusion.model.load_autoencoder()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsfkMkFwEAas"
   },
   "outputs": [],
   "source": [
    "# the autoencoder has a method to load the encoder, since it's one of its submodels. it returns the encoder\n",
    "stable_diffusion.model.autoencoder.load_encoder()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Uw9cFIgEAas"
   },
   "outputs": [],
   "source": [
    "# since each method returns the thing it loads, we could, for convenience, one-line that out: intialize a latent diffusion model, then load the autoencoder, then load the encoder\n",
    "stable_diffusion.quick_initialize().load_autoencoder().load_encoder()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BckgQOFhEAat"
   },
   "outputs": [],
   "source": [
    "# load an image to test the encoder module\n",
    "img = load_img(join(base_directory, \"test/test_images/test_img.jpg\")).to(device)\n",
    "to_pil(img.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDO9qxk5EAat"
   },
   "outputs": [],
   "source": [
    "# get the latent representation of the test image\n",
    "encoded_img = stable_diffusion.encode(img)\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hotnMi1IEAau"
   },
   "outputs": [],
   "source": [
    "# check its shape\n",
    "encoded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eb_9ba3EAau"
   },
   "outputs": [],
   "source": [
    "# show each dimension of the latent representation\n",
    "grid = torchvision.utils.make_grid(\n",
    "    encoded_img.permute(1, 0, 2, 3),\n",
    "    nrow=2,\n",
    "    normalize=False,\n",
    "    range=(-1, 1),\n",
    "    scale_each=True,\n",
    "    pad_value=0,\n",
    ")\n",
    "dim_grid_image = to_pil(grid)\n",
    "dim_grid_image.save(join(output_directory, f\"encoding_dimensions_grid.png\"))\n",
    "dim_grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2cDNYsREAau"
   },
   "outputs": [],
   "source": [
    "# save it as a tensor\n",
    "torch.save(encoded_img, join(output_base_dir, f\"encoded_img_tensor.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De2zHovcEAau"
   },
   "outputs": [],
   "source": [
    "del encoded_img\n",
    "torch.cuda.empty_cache()\n",
    "print(get_memory_status(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSogPR5IEAav"
   },
   "outputs": [],
   "source": [
    "# load it back\n",
    "encoded_img = torch.load(join(output_base_dir, f\"encoded_img_tensor.pt\"))\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDsK5NOzEAav"
   },
   "outputs": [],
   "source": [
    "encoded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjNXIA6LEAav"
   },
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(\n",
    "    encoded_img.permute(1, 0, 2, 3),\n",
    "    nrow=2,\n",
    "    normalize=False,\n",
    "    range=(-1, 1),\n",
    "    scale_each=True,\n",
    "    pad_value=0,\n",
    ")\n",
    "to_pil(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3g8Vo45EAav"
   },
   "outputs": [],
   "source": [
    "del grid\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjyF1xagEAaw"
   },
   "outputs": [],
   "source": [
    "# unload the encoder submodel\n",
    "stable_diffusion.model.autoencoder.unload_encoder()\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbxxvqXfEAaw"
   },
   "outputs": [],
   "source": [
    "# load the decoder submodel\n",
    "stable_diffusion.model.autoencoder.load_decoder()\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWKbpbKuEAaw"
   },
   "outputs": [],
   "source": [
    "# decode the latent representation that we loaded from disk\n",
    "decoded_img = stable_diffusion.decode(encoded_img)\n",
    "save_images(decoded_img, join(output_directory, f\"decoded_img.png\"))\n",
    "torch.cuda.empty_cache()\n",
    "get_memory_status(device)\n",
    "to_pil(decoded_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCCuGjvdEAaw"
   },
   "outputs": [],
   "source": [
    "# initially loaded image isn't the same as the decoded image\n",
    "torch.norm(img - decoded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0JFFS3zEAax"
   },
   "outputs": [],
   "source": [
    "# plot the difference as an image\n",
    "diff_img = to_pil((img - decoded_img).squeeze(0))\n",
    "diff_img.save(join(output_directory, f\"diff_img.png\"))\n",
    "diff_img"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
